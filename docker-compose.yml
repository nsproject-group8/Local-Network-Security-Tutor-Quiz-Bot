services:
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    volumes:
      - ./backend:/app/backend:delegated
      - ./data/chroma_db:/app/data/chroma_db
      - ./data/uploads:/app/data/uploads
      - ./logs:/app/logs
    env_file:
      - .env
    environment:
      - PYTHONUNBUFFERED=1
      # Ensure the backend talks to the Ollama service inside the compose
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      - ollama
    ports:
      - "8000:8000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8000/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 6

  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
      args:
        VITE_API_URL: "http://backend:8000"
    environment:
      - VITE_API_URL=http://backend:8000
    ports:
      - "3000:3000"
    depends_on:
      - backend
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    # If you want persistent model storage or config, mount a volume here.
    # volumes:
    #   - ./data/ollama:/var/lib/ollama
    ports:
      - "11434:11434"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:11434/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 6
